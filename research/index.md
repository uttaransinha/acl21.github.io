---
layout: page
title: Research
tags: [research, akshay, chandra, lagandula, iith, active learning]
modified: 2014-08-08T20:53:07.573882-04:00
comments: false
---

My interests broadly lie in the fields of computer vision, machine learning and learning with limited labeled data (mainly active learning).
I recently got interested in understanding how deep active learning can be accelerated. 

### Publications

1. **Akshay L Chandra**, S.V. Desai, Vineeth N Balasubramanian, S. Ninomiya, Wei Guo  
[Active Learning with Point Supervision for Cost-Effective Panicle Detection in Cereal Crops]()  
*BioMed Central Plant Methods Journal (BMC), 2020*  <span style="color:blue;font-size:12px" >[Impact Factor: 4.6]  
[<button type="button" class="btn btn-success">Poster</button>]()
[<button type="button" class="btn btn-danger">ArXiv</button>](http://arxiv.org/abs/1910.01789)
[<button type="button" class="btn btn-info">Code</button>]()
<!-- [<button type="button" class="btn btn-warning">Code</button>]()  -->
<!-- [<button type="button" class="btn">Video</button>]() -->

2. **Akshay L Chandra**<sup>&dagger;</sup>, S.V. Desai<sup>&dagger;</sup>, Wei Guo, S. Ninomiya, Vineeth N Balasubramanian  
[An Adaptive Supervision Framework for Active Learning in Object Detection](https://arxiv.org/abs/1908.02454)  
*British Machine Vision Conference (BMVC), 2019*  
<sup><sup>&dagger;</sup> Equal Contribution</sup>  
[<button type="button" class="btn btn-success">Poster</button>](/reports/bmvc19-poster.pdf)
[<button type="button" class="btn btn-danger">ArXiv</button>](https://arxiv.org/abs/1908.02454)
[<button type="button" class="btn btn-info">Code</button>]()
<!-- [<button type="button" class="btn btn-warning">Code</button>]()  -->
<!-- [<button type="button" class="btn">Video</button>]() -->

### Other applied projects

* **Image & Bounding Box Annotation Slicer**  
*An Object Detection Data Transformer, April 2019*  
**Abstract:**  
This easy-to-use library is a data transformer mainly useful in Object Detection tasks. It slices images and their bounding box annotations into smaller tiles, both into specific sizes and into any arbitrarynumber of equal parts.  It can also resize them, both by specific sizes and by a resizing/scaling factor.  
[<button type="button" class="btn btn-warning">Docs</button>](https://image-bbox-slicer.readthedocs.io/)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/acl21/image_bbox_slicer)

* **Mouse Cursor Control With Facial Movements**  
*An HCI Application, October 2018*  
**Abstract:**  
This Human-Computer Interaction application in Python will allow you to control your mouse cursor with your facial movements, works with just your regular webcam. Its hands-free, no wearable hardware or sensors needed.  
[<button type="button" class="btn btn-warning">Post</button>](https://towardsdatascience.com/c16b0494a971)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/acl21/Mouse_Cursor_Control_Handsfree)
[<button type="button" class="btn">Video</button>](https://youtu.be/L2XUKeLD6N8)

* **Robust Morse Code Converter (Incomplete)**  
*A Fun Deep Learning Application, August 2018*  
**Abstract:**  
This 4-in-1 application can convert Morse Code signalled in 4 different ways in real time. Namely, flashlight toggles, eye winking, hand gestures and mouse clicks.  
[<button type="button" class="btn btn-info">Code</button>](https://github.com/acl21/MorseCode_Converter_DeepLearning)

* **Selfie Filters Using Facial Landmarks**  
*A Fun Facial Keypoints Application, May 2018*  
**Abstract:**  
This deep learning application in Python can put various sunglasses on a detected face (I am calling them 'Selfie Filters') by detecting the Facial Landmarks (15 unique points). These landmarks mark important areas of the face - the eyes, corners of the mouth, the nose, etc.  
[<button type="button" class="btn btn-warning">Post</button>](https://towardsdatascience.com/737547f73515)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/acl21/Selfie_Filters_OpenCV)
[<button type="button" class="btn">Video</button>](https://youtu.be/tithrF0XNk0)

* **Alphabet Recognition Through Gestures**  
*A Gesture Recognition Application, April 2018*  
**Abstract:**  
This deep learning application in python recognizes alphabet through gestures captured real time on a webcam. The user is allowed to write the alphabet on the screen using an object-of-interest (a water bottle cap in this case).  
[<button type="button" class="btn btn-warning">Post</button>](https://towardsdatascience.com/97e697b8fb86)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/acl21/Alphabet_Recognition_Gestures)
[<button type="button" class="btn">Video</button>](https://youtu.be/NLcrlssOGBY)
